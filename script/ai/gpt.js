globalThis.AI=globalThis.AI||{},globalThis.AI.OpenAI={},globalThis.AI.MoonShot={},globalThis.AI.DeepSeek={},globalThis.AI.GLM={};let DefaultOpenAIChatModel=AI2Model.openai[0],DefaultOpenAIDrawModel="dall-e-3",DefaultMoonShotChatModel=AI2Model.moonshot[0],DefaultDeepSeekChatModel=AI2Model.deepseek[0],DefaultGLMChatModel=AI2Model.glm[0],DefaultGLMDrawModel="cogview-3-plus",assembleMessages=(e,r=!0,n=!0)=>{var s=[];return e.forEach(e=>{var t,a=e[1],o=null,e=("system"===e[0]?n?t="system":(t="user",a=e[1]+"\n\nKeep in mind the above requirements and instructions.",o={role:"assistant",content:r?[{type:"text",text:"I remembered it."}]:"I remembered it."}):"human"===e[0]?t="user":"ai"===e[0]&&(t="assistant"),r?[{type:"text",text:a}]:a);s.push({role:t,content:e}),o&&s.push(o)}),s},assembleDataPack=(e,t,a,o)=>{var r=Model2AI[e],n=Object.assign({},ModelDefaultConfig[r].header,(ModelDefaultConfig[e]||{}).header||{}),r=Object.assign({},ModelDefaultConfig[r].chat,(ModelDefaultConfig[e]||{}).chat||{},a||{});return n.Authorization="Bearer "+o,r.model=e,r.messages=t,[n,r]},scoreContent=e=>{var t=0;return e=(e=(e=e.replace(/[a-zA-Z]+/g,()=>(t+=2.5," "))).replace(/[\d\.]+/g,()=>(t+=1," "))).replace(/[\u4e00-\u9fa5]/g,()=>(t+=1," ")),Math.floor(t)};AI.OpenAI.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.openai}},a=Date.now();try{e=await waitUntil(fetch("https://api.openai.com/v1/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("OpenAI","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.OpenAI.chat=async(e,t=DefaultOpenAIChatModel,a={})=>{var o,r="o1-preview"===t||"o1-mini"===t,e=assembleMessages(e,!0,!r),[e,a]=assembleDataPack(t,e,a,myInfo.apiKey.openai),r=(r&&(a.max_completion_tokens=a.max_tokens,delete a.max_tokens),{method:"POST",headers:e,body:JSON.stringify(a)}),e=Date.now();try{await requestRateLimitLock(t),updateRateLimitLock(t,!0),o=await waitUntil(fetch("https://api.openai.com/v1/chat/completions",r)),updateRateLimitLock(t,!1)}catch(e){throw updateRateLimitLock(t,!1),e}e=Date.now()-e,logger.info("OpenAI","Chat: "+e/1e3+"s");a=await o.text();logger.info("OpenAI","Got Reply",a);try{a.match(/^\s*b'\{[\w\W]+\}'\s*$/)&&(a=a.replace(/^\s*b'|'\s*$/g,"").replace(/\\n/g,"\n")),o=JSON.parse(a)}catch(e){logger.error("OpenAI",e),o={}}r=o,t=o.usage,t&&(logger.info("OpenAI",`Usage: Input ${t.prompt_tokens}, Output: `+t.completion_tokens),AIUsage.request++,AIUsage.input+=t.prompt_tokens,AIUsage.output+=t.completion_tokens),e=o.choices;if(e=(e=e&&e[0])&&e.message?.content)return e=e.trim();throw e="",a=r.error?.message||"Error Occur!",logger.error("OpenAI",a),new Error(a)},AI.OpenAI.draw=async(e,t=DefaultOpenAIDrawModel,a={})=>{t={model:t,prompt:e,n:a.n||1,quality:a.quality||"standard",size:a.size||"1024x1024",style:a.style||"vivid"},e={method:"POST",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.openai},body:JSON.stringify(t)},a=Date.now();try{o=await waitUntil(fetch("https://api.openai.com/v1/images/generations",e))}catch(e){throw e}a=Date.now()-a,logger.info("OpenAI","Chat: "+a/1e3+"s");var o,t=o=await o.json(),e=o.data;if(e)return e=e.map(e=>e.url);throw a=t.error?.message||"Error Occur!",logger.error("OpenAI",a),new Error(a)},AI.MoonShot.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.moonshot}},a=Date.now();try{e=await waitUntil(fetch("https://api.moonshot.cn/v1/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("MoonShot","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.MoonShot.chat=async(e,t=DefaultMoonShotChatModel,a={})=>{var e=assembleMessages(e,!1),[e,a]=assembleDataPack(t,e,a,myInfo.apiKey.moonshot),e={method:"POST",headers:e,body:JSON.stringify(a)},a=Date.now();try{await requestRateLimitLock(t),updateRateLimitLock(t,!0),o=await waitUntil(fetch("https://api.moonshot.cn/v1/chat/completions",e)),updateRateLimitLock(t,!1)}catch(e){throw updateRateLimitLock(t,!1),e}a=Date.now()-a,logger.info("MoonShot","Chat: "+a/1e3+"s");var o,e=o=await o.json(),t=o.usage,a=(t&&(logger.info("MoonShot",`Usage: Input ${t.prompt_tokens}, Output: `+t.completion_tokens),AIUsage.request++,AIUsage.input+=t.prompt_tokens,AIUsage.output+=t.completion_tokens),o.choices);if(a=(a=a&&a[0])&&a.message?.content)return a=a.trim();throw a="",t=e.error?.message||"Error Occur!",logger.error("MoonShot",t),new Error(t)},AI.DeepSeek.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Accept:"application/json",Authorization:"Bearer "+myInfo.apiKey.deepseek}},a=Date.now();try{e=await waitUntil(fetch("https://api.deepseek.com/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("DeepSeek","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.DeepSeek.chat=async(e,t=DefaultDeepSeekChatModel,a={})=>{var e=assembleMessages(e,!1),[e,a]=assembleDataPack(t,e,a,myInfo.apiKey.deepseek),e={method:"POST",headers:e,body:JSON.stringify(a)},a=Date.now();try{await requestRateLimitLock(t),updateRateLimitLock(t,!0),o=await waitUntil(fetch("https://api.deepseek.com/beta/chat/completions",e)),updateRateLimitLock(t,!1)}catch(e){throw updateRateLimitLock(t,!1),e}a=Date.now()-a,logger.info("DeepSeek","Chat: "+a/1e3+"s");var o,e=o=await o.json(),t=o.usage,a=(t&&(logger.info("DeepSeek",`Usage: Input ${t.prompt_tokens}, Output: `+t.completion_tokens),AIUsage.request++,AIUsage.input+=t.prompt_tokens,AIUsage.output+=t.completion_tokens),o.choices);if(a=(a=a&&a[0])&&a.message?.content)return a=a.trim();throw a="",t=e.error?.message||"Error Occur!",logger.error("DeepSeek",t),new Error(t)},AI.GLM.chat=async(e,t=DefaultGLMChatModel,a={})=>{var e=assembleMessages(e,!1),o=JWSgenerate(myInfo.apiKey.glm,31536e3),[e,a]=assembleDataPack(t,e,a,o),o={method:"POST",headers:e,body:JSON.stringify(a)},e=Date.now();try{await requestRateLimitLock(t),updateRateLimitLock(t,!0),r=await waitUntil(fetch("https://open.bigmodel.cn/api/paas/v4/chat/completions",o)),updateRateLimitLock(t,!1)}catch(e){throw updateRateLimitLock(t,!1),e}e=Date.now()-e,logger.info("GLM","Chat: "+e/1e3+"s");var r,a=r=await r.json(),o=r.usage,t=(o&&(logger.info("GLM",`Usage: Input ${o.prompt_tokens}, Output: `+o.completion_tokens),AIUsage.request++,AIUsage.input+=o.prompt_tokens,AIUsage.output+=o.completion_tokens),r.choices);if(t=(t=t&&t[0])&&t.message?.content)return t=t.trim();throw t="",e=a.error?.message||"Error Occur!",logger.error("GLM",e),new Error(e)},AI.GLM.draw=async(e,t=DefaultGLMDrawModel,a={})=>{t={model:t,prompt:e,n:a.n||1,quality:a.quality||"standard",size:a.size||"1024x1024",style:a.style||"vivid"},e={method:"POST",headers:{"Content-Type":"application/json",Authorization:"Bearer "+JWSgenerate(myInfo.apiKey.glm,31536e3)},body:JSON.stringify(t)},a=Date.now();try{o=await waitUntil(fetch("https://open.bigmodel.cn/api/paas/v4/images/generations",e))}catch(e){throw e}a=Date.now()-a,logger.info("GLM","Chat: "+a/1e3+"s");var o,t=o=await o.json(),e=o.data;if(e)return e=e.map(e=>e.url);throw a=t.error?.message||"Error Occur!",logger.error("GLM",a),new Error(a)};