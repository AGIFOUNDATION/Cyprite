globalThis.AI=globalThis.AI||{},globalThis.AI.OpenAI={},globalThis.AI.MoonShot={},globalThis.AI.DeepSeek={},globalThis.AI.GLM={},globalThis.AI.MiniMax={},globalThis.AI.Mixtral={};let DefaultOpenAIChatModel=AI2Model.openai[0],DefaultOpenAIDrawModel="dall-e-3",DefaultMoonShotChatModel=AI2Model.moonshot[0],DefaultDeepSeekChatModel=AI2Model.deepseek[0],DefaultGLMChatModel=AI2Model.glm[0],DefaultGLMDrawModel="cogview-3-plus",DefaultMiniMaxChatModel=AI2Model.minimax[0],DefaultMixtralChatModel=AI2Model.mixtral[0],assembleMessages=(e,i=!0,s=!0)=>{var r=[];return e.forEach(e=>{var t,a=e[1],o=null,e=("system"===e[0]?s?t="system":(t="user",a=e[1]+"\n\nKeep in mind the above requirements and instructions.",o={role:"assistant",content:i?[{type:"text",text:"I remembered it."}]:"I remembered it."}):"human"===e[0]?t="user":"ai"===e[0]&&(t="assistant"),i?[{type:"text",text:a}]:a);r.push({role:t,content:e}),o&&r.push(o)}),r},assembleDataPack=(e,t,a)=>{var o=Model2AI[e],i=Object.assign({},ModelDefaultConfig[o].header,(ModelDefaultConfig[e]||{}).header||{}),o=Object.assign({},ModelDefaultConfig[o].chat,(ModelDefaultConfig[e]||{}).chat||{},t||{});return i.Authorization="Bearer "+a,o.model=e,[i,o]};AI.OpenAI.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.openai}},a=Date.now();try{e=await waitUntil(fetchWithCheck("https://api.openai.com/v1/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("OpenAI","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.OpenAI.chat=async(s,r=DefaultOpenAIChatModel,e={})=>{for(var n="o1-preview"===r||"o1-mini"===r,p=assembleMessages(s,!0,!n),[e,u]=assembleDataPack(r,e,myInfo.apiKey.openai),h=(u.messages=p,n&&(u.max_completion_tokens=u.max_tokens,delete u.max_tokens),{method:"POST",headers:e,body:JSON.stringify(u)}),l=[],c={count:0,input:0,output:0},m=!0,e=Date.now(),g=0;;){let t;try{await requestRateLimitLock(r),updateRateLimitLock(r,!0),t=await waitUntil(fetchWithCheck("https://api.openai.com/v1/chat/completions",h)),updateRateLimitLock(r,!1)}catch(e){throw updateRateLimitLock(r,!1),e}let e=await t.text();try{e.match(/^\s*b'\{[\w\W]+\}'\s*$/)&&(e=e.replace(/^\s*b'|'\s*$/g,"").replace(/\\n/g,"\n")),t=JSON.parse(e)}catch(e){logger.error("OpenAI",e),t={}}logger.info("OpenAI",t);var d=t.error;if(d&&d.message)throw new Error(d.message);let a=t.usage,o=t.choices,i=(c.count++,a&&(c.input+=a.prompt_tokens,c.output+=a.completion_tokens),"");if((o=o&&o[0])&&(i=o.finish_reason||"",o=o.message?.content),!o)throw o="",d=t.error?.message||"Error Occur!",logger.error("OpenAI",d),new Error(d);if(o=o.trim(),l.push(o),"length"!==i.toLowerCase())break;if(m?(s.push(["ai",o]),s.push(["human",PromptLib.continueOutput]),m=!1):s[s.length-2][1]=l.join(" "),p=assembleMessages(s,!0,!n),u.messages=p,h.body=JSON.stringify(u),++g>=ModelContinueRequestLoopLimit)break}return e=Date.now()-e,logger.info("OpenAI","Timespent: "+e/1e3+"s; Input: "+c.input+"; Output: "+c.output),recordAIUsage(r,"OpenAI",c),l.join(" ")},AI.OpenAI.draw=async(e,t=DefaultOpenAIDrawModel,a={})=>{t={model:t,prompt:e,n:a.n||1,quality:a.quality||"standard",size:a.size||"1024x1024",style:a.style||"vivid"},e={method:"POST",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.openai},body:JSON.stringify(t)},a=Date.now();try{o=await waitUntil(fetchWithCheck("https://api.openai.com/v1/images/generations",e))}catch(e){throw e}a=Date.now()-a,logger.info("OpenAI","Chat: "+a/1e3+"s");var o,t=o=await o.json(),e=o.data;if(e)return e=e.map(e=>e.url);throw a=t.error?.message||"Error Occur!",logger.error("OpenAI",a),new Error(a)},AI.MoonShot.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Authorization:"Bearer "+myInfo.apiKey.moonshot}},a=Date.now();try{e=await waitUntil(fetchWithCheck("https://api.moonshot.cn/v1/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("MoonShot","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.MoonShot.chat=async(o,i=DefaultMoonShotChatModel,e={})=>{for(var s=assembleMessages(o,!1),[e,r]=assembleDataPack(i,e,myInfo.apiKey.moonshot),n=(r.messages=s,{method:"POST",headers:e,body:JSON.stringify(r)}),p=[],u={count:0,input:0,output:0},h=!0,e=Date.now(),l=0;;){let e;try{await requestRateLimitLock(i),updateRateLimitLock(i,!0),e=await waitUntil(fetchWithCheck("https://api.moonshot.cn/v1/chat/completions",n)),updateRateLimitLock(i,!1)}catch(e){throw updateRateLimitLock(i,!1),e}e=await e.json(),logger.info("MoonShot",e);var c=e.error;if(c&&c.message)throw new Error(c.message);let t=e.usage,a=e.choices;u.count++,t&&(u.input+=t.prompt_tokens,u.output+=t.completion_tokens);var m,c=(a=a&&a[0]).finish_reason||"";if(!(a=a&&a.message?.content))throw a="",m=e.error?.message||"Error Occur!",logger.error("MoonShot",m),new Error(m);if(a=a.trim(),p.push(a),"length"!==c.toLowerCase())break;if(h?(o.push(["ai",a]),o.push(["human",PromptLib.continueOutput]),h=!1):o[o.length-2][1]=p.join(" "),s=assembleMessages(o,!1),r.messages=s,n.body=JSON.stringify(r),++l>=ModelContinueRequestLoopLimit)break}return e=Date.now()-e,logger.info("MoonShot","Timespent: "+e/1e3+"s; Input: "+u.input+"; Output: "+u.output),recordAIUsage(i,"MoonShot",u),p.join(" ")},AI.DeepSeek.list=async()=>{var e,t={method:"GET",headers:{"Content-Type":"application/json",Accept:"application/json",Authorization:"Bearer "+myInfo.apiKey.deepseek}},a=Date.now();try{e=await waitUntil(fetchWithCheck("https://api.deepseek.com/models",t))}catch(e){throw e}return a=Date.now()-a,logger.info("DeepSeek","List: "+a/1e3+"s"),e=(e=await e.json()).data||e},AI.DeepSeek.chat=async(o,i=DefaultDeepSeekChatModel,e={})=>{for(var s=assembleMessages(o,!1),[e,r]=assembleDataPack(i,e,myInfo.apiKey.deepseek),n=(r.messages=s,{method:"POST",headers:e,body:JSON.stringify(r)}),p=[],u={count:0,input:0,output:0},h=!0,e=Date.now(),l=0;;){let e;try{await requestRateLimitLock(i),updateRateLimitLock(i,!0),e=await waitUntil(fetchWithCheck("https://api.deepseek.com/beta/chat/completions",n)),updateRateLimitLock(i,!1)}catch(e){throw updateRateLimitLock(i,!1),e}e=await e.json(),logger.info("DeepSeek",e);var c=e.error;if(c&&c.message)throw new Error(c.message);let t=e.usage,a=e.choices;u.count++,t&&(u.input+=t.prompt_tokens,u.output+=t.completion_tokens);var m,c=(a=a&&a[0]).finish_reason||"";if(!(a=a&&a.message?.content))throw a="",m=e.error?.message||"Error Occur!",logger.error("DeepSeek",m),new Error(m);if(a=a.trim(),p.push(a),"length"!==c.toLowerCase())break;if(h?(o.push(["ai",a]),o.push(["human",PromptLib.continueOutput]),h=!1):o[o.length-2][1]=p.join(" "),s=assembleMessages(o,!1),r.messages=s,n.body=JSON.stringify(r),++l>=ModelContinueRequestLoopLimit)break}return e=Date.now()-e,logger.info("DeepSeek","Timespent: "+e/1e3+"s; Input: "+u.input+"; Output: "+u.output),recordAIUsage(i,"DeepSeek",u),p.join(" ")},AI.GLM.chat=async(o,i=DefaultGLMChatModel,e={})=>{for(var s=assembleMessages(o,!1),t=JWSgenerate(myInfo.apiKey.glm,31536e3),[e,r]=assembleDataPack(i,e,t),n=(r.messages=s,{method:"POST",headers:e,body:JSON.stringify(r)}),p=[],u={count:0,input:0,output:0},h=!0,t=Date.now(),l=0;;){let e;try{await requestRateLimitLock(i),updateRateLimitLock(i,!0),e=await waitUntil(fetchWithCheck("https://open.bigmodel.cn/api/paas/v4/chat/completions",n)),updateRateLimitLock(i,!1)}catch(e){throw updateRateLimitLock(i,!1),e}e=await e.json(),logger.info("GLM",e);var c=e.error;if(c&&c.message)throw new Error(c.message);let t=e.usage,a=e.choices;u.count++,t&&(u.input+=t.prompt_tokens,u.output+=t.completion_tokens);var m,c=(a=a&&a[0]).finish_reason||"";if(!(a=a&&a.message?.content))throw a="",m=e.error?.message||"Error Occur!",logger.error("GLM",m),new Error(m);if(a=a.trim(),p.push(a),"length"!==c.toLowerCase())break;if(h?(o.push(["ai",a]),o.push(["human",PromptLib.continueOutput]),h=!1):o[o.length-2][1]=p.join(" "),s=assembleMessages(o,!1),r.messages=s,n.body=JSON.stringify(r),++l>=ModelContinueRequestLoopLimit)break}return t=Date.now()-t,logger.info("GLM","Timespent: "+t/1e3+"s; Input: "+u.input+"; Output: "+u.output),recordAIUsage(i,"GLM",u),p.join(" ")},AI.GLM.draw=async(e,t=DefaultGLMDrawModel,a={})=>{t={model:t,prompt:e,n:a.n||1,quality:a.quality||"standard",size:a.size||"1024x1024",style:a.style||"vivid"},e={method:"POST",headers:{"Content-Type":"application/json",Authorization:"Bearer "+JWSgenerate(myInfo.apiKey.glm,31536e3)},body:JSON.stringify(t)},a=Date.now();try{o=await waitUntil(fetchWithCheck("https://open.bigmodel.cn/api/paas/v4/images/generations",e))}catch(e){throw e}a=Date.now()-a,logger.info("GLM","Chat: "+a/1e3+"s");var o,t=o=await o.json(),e=o.data;if(e)return e=e.map(e=>e.url);throw a=t.error?.message||"Error Occur!",logger.error("GLM",a),new Error(a)},AI.MiniMax.chat=async(i,s=DefaultMiniMaxChatModel,e={})=>{for(var r=assembleMessages(i,!1),[e,n]=assembleDataPack(s,e,myInfo.apiKey.minimax),p=(n.messages=r,{method:"POST",headers:e,body:JSON.stringify(n)}),u=[],h={count:0,input:0,output:0},l=!0,e=Date.now(),c=0;;){let e;try{await requestRateLimitLock(s),updateRateLimitLock(s,!0),e=await waitUntil(fetchWithCheck("https://api.minimax.chat/v1/text/chatcompletion_v2",p)),updateRateLimitLock(s,!1)}catch(e){throw updateRateLimitLock(s,!1),e}e=await e.json(),logger.info("MiniMax",e);var m=e.error;if(m&&m.message)throw new Error(m.message);let t=e.usage,a=e.choices,o=(h.count++,t&&(h.output+=t.total_tokens),"");if((a=a&&a[0])&&(a=a.message?.content,o=a.finish_reason||""),!a)throw a="",m=e.base_resp?.status_msg||"Error Occur!",logger.error("MiniMax",m),new Error(m);if(a=a.trim(),u.push(a),"length"!==o.toLowerCase())break;if(l?(i.push(["ai",a]),i.push(["human",PromptLib.continueOutput]),l=!1):i[i.length-2][1]=u.join(" "),r=assembleMessages(i,!1),n.messages=r,p.body=JSON.stringify(n),++c>=ModelContinueRequestLoopLimit)break}return e=Date.now()-e,logger.info("MiniMax","Timespent: "+e/1e3+"s; Input: "+h.input+"; Output: "+h.output),recordAIUsage(s,"MiniMax",h),u.join(" ")},AI.Mixtral.chat=async(i,s=DefaultMixtralChatModel,e={})=>{for(var r=assembleMessages(i,!1),[e,n]=assembleDataPack(s,e,myInfo.apiKey.mixtral),p=(n.messages=r,{method:"POST",headers:e,body:JSON.stringify(n)}),u=[],h={count:0,input:0,output:0},l=!0,e=Date.now(),c=0;;){let e;try{await requestRateLimitLock(s),updateRateLimitLock(s,!0),e=await waitUntil(fetchWithCheck("https://api.mistral.ai/v1/chat/completions",p)),updateRateLimitLock(s,!1)}catch(e){throw updateRateLimitLock(s,!1),e}e=await e.json(),logger.info("Mixtral",e);var m=e.detail;if(m&&m[0]&&m[0].msg)throw new Error(m[0].msg);let t=e.usage,a=e.choices,o=(h.count++,t&&(h.input+=t.prompt_tokens,h.output+=t.completion_tokens),"");if((a=a&&a[0])&&(a=a.message?.content,o=a.finish_reason||""),!a)throw a="",m=m||"Error Occur!",logger.error("Mixtral",m),new Error(m);if(a=a.trim(),u.push(a),"length"!==o.toLowerCase())break;if(l?(i.push(["ai",a]),i.push(["human",PromptLib.continueOutput]),l=!1):i[i.length-2][1]=u.join(" "),r=assembleMessages(i,!1),n.messages=r,p.body=JSON.stringify(n),++c>=ModelContinueRequestLoopLimit)break}return e=Date.now()-e,logger.info("Mixtral","Timespent: "+e/1e3+"s; Input: "+h.input+"; Output: "+h.output),recordAIUsage(s,"Mixtral",h),u.join(" ")};