import"./ai/prompts.js";import"./ai/gemini.js";import"./ai/claude.js";import"./ai/gpt.js";import"./ai/ernie.js";import"./ai/groq.js";let ResMap=new Map,EmbeddingLimit=2024;var synchronousCount=0,embedAIModel=AI.Gemini.embed;const LLMUsage={},ModelUsage={};globalThis.recordAIUsage=(e,t,a)=>{var r=LLMUsage[t],t=(r||(r={count:0,input:0,output:0},LLMUsage[t]=r),r.count+=a.count,r.input+=a.input,r.output+=a.output,(r=ModelUsage[e])||(r={count:0,input:0,output:0},ModelUsage[e]=r),r.count+=a.count,r.input+=a.input,r.output+=a.output,{llm_usage_record:LLMUsage,model_usage_record:ModelUsage});chrome.storage.local.set(t)},globalThis.showAIUsage=async()=>{await loadAIUsage(),logger.em("AI USAGE","LLM Usage:");var e,t,a=[];for(e in LLMUsage){var r=LLMUsage[e];a.push({LLM:e,count:r.count,input:r.input,output:r.output})}for(t in console.table(a,["LLM","count","input","output"]),logger.em("AI USAGE","Model Usage:"),a=[],ModelUsage){var s=ModelUsage[t];a.push({model:t,count:s.count,input:s.input,output:s.output})}console.table(a,["model","count","input","output"])},globalThis.resetAIUsage=()=>{LLMUsage={},ModelUsage={},chrome.storage.local.remove(["llm_usage_record","model_usage_record"])},globalThis.loadAIUsage=async()=>{var e=await chrome.storage.local.get(["llm_usage_record","model_usage_record"]),t=e.llm_usage_record,a=e.model_usage_record;if(t)for(var r in t)LLMUsage[r]=t[r];if(a)for(var s in a)ModelUsage[s]=a[s]},showAIUsage(),globalThis.callAIandWait=(n,o)=>new Promise(async(t,a)=>{myInfo.inited||await getWSConfig();var r,s=newID();if(ForceBackend)if(sendMessage===DefaultSendMessage)a("No AI Server Available");else try{t(await callServer(n,o))}catch(e){a(e)}else{let e=!0;if(!myInfo.useLocalKV&&sendMessage!==DefaultSendMessage){e=!1;try{t(await callServer(n,o))}catch{e=!0}}e&&(myInfo.edgeAvailable?(r=EdgedAI[n])?(ResMap.set(s,[t,a]),r(s,o)):(t="NO such action: "+n,logger.error("AI",t),a(t)):(r=I18NMessages[myInfo.lang]||I18NMessages[DefaultLang],console.error(r.noAPIKey,JSON.parse(JSON.stringify(myInfo))),chrome.notifications.create({title:r.cypriteName,message:r.noAPIKey,type:"basic",iconUrl:"/images/icon1024.png"}),a(r.noAPIKey)))}});let replyRequest=(e,t,a)=>{var r=ResMap.get(e);r&&(ResMap.delete(e),a?r[1](a):r[0](t))},splitParagraph=(r,e)=>{var s=[],n=0;return(r="\n"+r).replace(new RegExp("\\n"+e+"\\s+","gi"),(e,t)=>{var a=r.substring(n,t);n=t,a=a.trim(),s.push(a)}),s.push(r.substring(n).trim()),s=(s=s.filter(e=>!!e)).map(e=>e.length>EmbeddingLimit?[!1,e]:[!0,e])},splitSentence=(r,e,a=!1)=>{var s=[],n=0,o=(r.replace(e,(e,...t)=>{t.some(e=>{if(isNumber(e))return a=e,!0}),a+=e.length;var a,t=r.substring(n,a);n=a,s.push(t)}),s.push(r.substring(n)),s=s.filter(e=>!!e.trim()),[]),i=0,l="",g=a?1:0;return s.forEach(e=>{var t=e.length;t>EmbeddingLimit?(o.push([!0,l.trim()]),l="",i=0,o.push([!1,e.trim()])):i=i+t+g>EmbeddingLimit?(o.push([!0,l.trim()]),l=e,t):(a?l=l+"\n"+e:l+=e,l.length)}),l.trim()&&o.push([!0,l.trim()]),o},batchize=e=>e=(e=(e=(e=splitParagraph(e,"#")).map(e=>e[0]?e[1]:e=(e=splitParagraph(e[1],"##")).map(e=>e[0]?e[1]:e=(e=splitParagraph(e[1],"###")).map(e=>e[0]?e[1]:e=(e=splitParagraph(e[1],"####")).map(e=>e[0]?e[1]:e=(e=splitSentence(e[1],/(\r*\n\r*)+/g,!0)).map(e=>e[0]?e[1]:e=(e=splitSentence(e[1],/[\.\?\!。？！…]['"’”]?/gi)).map(e=>e[0]?e[1]:e=(e=splitSentence(e[1],/[,;，；]['"’”]?\s*/gi)).map(e=>e[0]?e[1]:e=(e=splitSentence(e[1],/\s+/gi)).map(t=>{if(t[0])return t[1];t=t[1];var a=[],r=Math.ceil(t.length/EmbeddingLimit),s=Math.ceil(t.length/r);for(let e=0;e<r;e++){var n=e*s,n=t.substring(n,n+s);a.push(n)}return a}))))))))).flat(1/0)).filter(e=>!!e),callEdgeAI=async(e,t,a)=>{if(t=t.map(e=>[...e]),a=a||myInfo.model){var r,s,n=Model2AI[a],n=AI[n];if(n=n&&n.chat){synchronousCount++,logger.strong("AI-Start","Synchronous: "+synchronousCount);try{r=await n(t,a)}catch(e){s=isString(e)?new Error(e):e,r=null}synchronousCount--,logger.strong("AI-Finish","Synchronous: "+synchronousCount),replyRequest(e,r,s)}else replyRequest(e,null,new Error("No AI for Model "+a))}else replyRequest(e,null,new Error("AI Model not set."))},EdgedAI={sayHello:async e=>{return;var t=PromptLib.assemble(PromptLib.sayHello,{lang:LangName[myInfo.lang],name:myInfo.name,info:myInfo.info,time:timestmp2str(Date.now(),"YY年MM月DD日 :WDE: hh:mm")});callEdgeAI(e,[["human",t]])},summarizeArticle:async(e,t)=>{t=PromptLib.assemble(PromptLib.summarizeArticle,{article:t,lang:LangName[myInfo.lang]});callEdgeAI(e,[["human",t]])},embeddingArticle:async(e,a)=>{var t,r,s=[],n=a.article||a.summary;n.length>EmbeddingLimit?(n=batchize(n)).forEach((e,t)=>{s.push({title:a.title+"-"+(t+1),content:e})}):s.push({title:a.title,content:n});try{t=await embedAIModel(s)}catch(e){logger.error("Embedding",e),r=isString(e)?new Error(e):e}replyRequest(e,t,r)},directAskAI:async(e,t)=>{var a=myInfo.model;isObject(t)&&(a=t.model||a,t=t.conversation),callEdgeAI(e,t,a)},translateSentence:async(e,t)=>{var a=[];a.push(["human",PromptLib.assemble(PromptLib.instantTranslation,t)]),callEdgeAI(e,a)}};